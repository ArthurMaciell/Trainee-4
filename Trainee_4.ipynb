{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "T3E-u5NPmR_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vou usar a base de dados fornecida com as classes Cachorros, Gatos e Pandas para fazer uma rede convolucional do zero usando TensorFlow. Depois será feito uma comparação com uma rede pré-treinada para avaliar as diferenças entre os dois."
      ],
      "metadata": {
        "id": "FtxCYAyKmV9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "5LjE4pdFmW-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi necessário criar um diretorio origem e um diretório destino para que fosse feito a divisão entre os dados que seriam usados para o treinamento e os de teste."
      ],
      "metadata": {
        "id": "1zgL2Z_TmYso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diretorio_origem = 'animals'\n",
        "diretorio_destino = 'animalsd'\n",
        "\n",
        "splitfolders.ratio(diretorio_origem, output=diretorio_destino, seed=1337, ratio=(0.8,0.2))"
      ],
      "metadata": {
        "id": "2JhH_0K7mbZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para fazer a divisão entre os dados foi usado a função splitfolders que cria uma pasta train e uma val. Train é a de treinamento e val é a de validação (teste) da rede neural convolucional."
      ],
      "metadata": {
        "id": "pFfmNgJdmdz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida são os códigos usados para fazer a CNN."
      ],
      "metadata": {
        "id": "-JZQeuQSmfMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diretorio_treinamento = 'animalsd\\\\train'\n",
        "diretorio_teste = 'animalsd\\\\val'\n",
        "\n",
        "gerador_treinamento = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)\n",
        "\n",
        "dados_treinamento = gerador_treinamento.flow_from_directory(diretorio_treinamento,target_size=(224,224), batch_size = 32, class_mode='categorical')\n",
        "\n",
        "gerador_teste = ImageDataGenerator(rescale = 1.0/225)\n",
        "\n",
        "dados_teste = gerador_teste.flow_from_directory(diretorio_teste, target_size=(224,224), batch_size=32,class_mode='categorical')"
      ],
      "metadata": {
        "id": "6bN-O8mgmgXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = models.Sequential([layers.Conv2D(32,(3,3),activation='relu', input_shape=(224,224,3)),layers.MaxPooling2D((2,2)), layers.Conv2D(64,(3,3),activation='relu'),layers.MaxPooling2D((2,2)),layers.Conv2D(128,(3,3),activation='relu'),layers.MaxPooling2D((2,2)),layers.Flatten(),layers.Dense(128, activation='relu'),layers.Dense(3, activation='softmax')])"
      ],
      "metadata": {
        "id": "V_2tnyfZmhiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XmP5VBoRmiav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "E5fVFjYLmjk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.fit(dados_treinamento, epochs=10, validation_data = dados_teste)"
      ],
      "metadata": {
        "id": "fzMLR3SumkWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = modelo.evaluate(dados_teste)\n",
        "print(f'Acurácia :{resultados[1]*100:.2f}%')"
      ],
      "metadata": {
        "id": "W5-8l9bymlg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A acurácia do modelo utilizado deu em torno de 70%. Acredito que seja razoável mas poderíamos melhorar isso fazendo ajustando alguns hiperparâmetros, a taxa de aprendizado, o número de épocas."
      ],
      "metadata": {
        "id": "j9WAvcHKmm1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algo que poderia melhorar os resultados seriam fazer algumas alterações no código de aprendizagem como uma rotação aleatória de até 20 graus, deslocamento horizontal e vertical aleatório, corte lateral e zoom aleatório."
      ],
      "metadata": {
        "id": "x-a7JV3Gmn2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ],
      "metadata": {
        "id": "AtL1evlVmosK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui será feito o uso da base de dados pré-treinada."
      ],
      "metadata": {
        "id": "GjBgLDa_mpxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "num_classes = 3\n",
        "output_layer= tf.keras.layers.Dense(num_classes, activation ='softmax')(base_model.output)\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "model.compile(optimizer='adam',loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(diretorio_treinamento, epochs=10, validation_data=diretorio_teste)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(diretorio_teste)\n",
        "print(f'Acurácia no conjunto de teste: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "z2j3hlcwmq4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP\n"
      ],
      "metadata": {
        "id": "myfRVoAbmsG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n"
      ],
      "metadata": {
        "id": "-zxHbMh4ms-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text  = text.lower()\n",
        "\n",
        "    text = re.sub(r'[^a-zA-ZO-9/s]','',text)\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = [token.text for token in doc if token.text not in stop_words]"
      ],
      "metadata": {
        "id": "nbUO3L7WmuKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}